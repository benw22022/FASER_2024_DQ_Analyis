{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import uproot\n",
    "import mplhep as hep\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import boost_histogram as bh\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lumi_dict(grl_dir):\n",
    "    grl_csvs = glob.glob(os.path.join(grl_dir, \"*.csv\"))\n",
    "    lumi_dict = {}\n",
    "    for grl in grl_csvs:\n",
    "        with open(grl, 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i == 0: continue\n",
    "\n",
    "                spline = line.split(\",\")\n",
    "                lumi_rec = float(spline[3])\n",
    "                run_num = int(spline[0])\n",
    "                lumi_dict[run_num] = lumi_rec\n",
    "\n",
    "    return lumi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumi_dict = get_lumi_dict(\"/cvmfs/faser.cern.ch/repo/sw/runlist/v8/\")\n",
    "runs = np.array(list(lumi_dict.keys()))\n",
    "runs_2022 = runs[runs < 1e4]\n",
    "runs_2023 = runs[runs > 1e4]\n",
    "runs_2023 = runs_2023[runs_2023 < 1.2e4]\n",
    "runs_2024 = runs[runs > 1.2e4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10417, 10419, 10443, 10540, 10572, 10600, 10602, 10747, 10799, 11214, 11461, 11463, 11478, 11480, 11486, 11491, 11706, 7733, 7734, 7802, 7833, 7835, 7836, 7848, 7849, 7971, 7984, 7987, 7988, 7989, 7990, 7998, 8034, 8036, 8037, 8038, 8039, 8040, 8041, 8090, 8096, 8097, 8098, 8099, 8104, 8105, 8106, 8108, 8109, 8110, 8111, 8112, 8113, 8114, 8243, 8247, 8253, 8295, 8651, 8652, 8655, 8658, 8713, 8714, 8734, 8751, 8901, 8904, 8910, 8932, 9048, 9053, 9056, 9066, 9171, 14587, 14588, 14589, 14590, 14597, 14733, 14766, 14776, 15075, 15146, 15181, 15257, 15259, 15260, 15267, 15421, 15455, 15553, 15676, 15678, 15679, 15868, 15975, 15993, 16522, 16648, 16669, 16716]\n"
     ]
    }
   ],
   "source": [
    "low_lumi_runs = []\n",
    "for run, lumi in lumi_dict.items():\n",
    "    if lumi < 10: \n",
    "        low_lumi_runs.append(run)\n",
    "print(low_lumi_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of bad runs can be found on the twiki here: https://twiki.cern.ch/twiki/bin/view/FASER/BadFASERRuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_runs = [{'runs': [15694], \"reason\": \"ATLAS lumi unrealiable\"},\n",
    "            {'runs': [15415, 15418, 15421, 15422, 15424, 15425, 15429], \"reason\": \"TCL6 Collimator settings changed\"},\n",
    "            {'runs': [16100], \"reason\": \"LHC missing B2 trains\"},\n",
    "            {'runs': [16648, 16649], \"reason\": \"Bad filewriter state? (Not sure about this)\"},\n",
    "            {'runs': [16963], \"reason\": \"Missing LHC bunch trains\"},\n",
    "            {'runs': [10417, 10419, 10443, 10540, 10572, 10600, 10602, 10747, 10799, 11214, 11461, 11463, 11478, 11480, 11486, 11491, 11706, 7733, 7734, 7802, 7833, 7835, 7836, 7848, 7849, 7971, 7984, 7987, 7988, 7989, 7990, 7998, 8034, 8036, 8037, 8038, 8039, 8040, 8041, 8090, 8096, 8097, 8098, 8099, 8104, 8105, 8106, 8108, 8109, 8110, 8111, 8112, 8113, 8114, 8243, 8247, 8253, 8295, 8651, 8652, 8655, 8658, 8713, 8714, 8734, 8751, 8901, 8904, 8910, 8932, 9048, 9053, 9056, 9066, 9171, 14587, 14588, 14589, 14590, 14597, 14733, 14766, 14776, 15075, 15146, 15181, 15257, 15259, 15260, 15267, 15421, 15455, 15553, 15676, 15678, 15679, 15868, 15975, 15993, 16522, 16648, 16669, 16716], \"reason\": \"Run has < 10 /pb\"}\n",
    "           ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'runs': [15694], 'reason': 'ATLAS lumi unrealiable', 'lumi': 19.609}, {'runs': [15415, 15418, 15421, 15422, 15424, 15425, 15429], 'reason': 'TCL6 Collimator settings changed', 'lumi': 2884.161}, {'runs': [16100], 'reason': 'LHC missing B2 trains', 'lumi': 152.603}, {'runs': [16648, 16649], 'reason': 'Bad filewriter state? (Not sure about this)', 'lumi': 248.5}, {'runs': [16963], 'reason': 'Missing LHC bunch trains', 'lumi': 36.218}, {'runs': [10417, 10419, 10443, 10540, 10572, 10600, 10602, 10747, 10799, 11214, 11461, 11463, 11478, 11480, 11486, 11491, 11706, 7733, 7734, 7802, 7833, 7835, 7836, 7848, 7849, 7971, 7984, 7987, 7988, 7989, 7990, 7998, 8034, 8036, 8037, 8038, 8039, 8040, 8041, 8090, 8096, 8097, 8098, 8099, 8104, 8105, 8106, 8108, 8109, 8110, 8111, 8112, 8113, 8114, 8243, 8247, 8253, 8295, 8651, 8652, 8655, 8658, 8713, 8714, 8734, 8751, 8901, 8904, 8910, 8932, 9048, 9053, 9056, 9066, 9171, 14587, 14588, 14589, 14590, 14597, 14733, 14766, 14776, 15075, 15146, 15181, 15257, 15259, 15260, 15267, 15421, 15455, 15553, 15676, 15678, 15679, 15868, 15975, 15993, 16522, 16648, 16669, 16716], 'reason': 'Run has < 10 /pb', 'lumi': 281.3930000000001}]\n"
     ]
    }
   ],
   "source": [
    "for i, bad_run in enumerate(bad_runs):\n",
    "    lost_lumi = sum([lumi_dict[r] for r in bad_run['runs']])\n",
    "    bad_runs[i]['lumi'] = lost_lumi\n",
    "print(bad_runs)\n",
    "with open('bad_runs.json', 'w') as f:\n",
    "    json.dump(bad_runs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of the the different run periods for 2024 can be found here: https://docs.google.com/spreadsheets/d/1nnYFcmhVieSHI5XAVhPiW1K6CoGYGxv2YPchwL0sqH4/edit?gid=0#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_splits = []\n",
    "header = []\n",
    "with open(\"2024RunSplits.csv\", 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0: \n",
    "            header = line.split(',')\n",
    "            continue\n",
    "        \n",
    "        split_dict = {}\n",
    "        spline = line.split(',')\n",
    "        for key, value in zip(header, spline):\n",
    "            split_dict[key.strip()] = value.strip()   \n",
    "        run_splits.append(split_dict)\n",
    "\n",
    "with open(\"2024RunSplits.json\", 'w') as f:\n",
    "    json.dump(run_splits, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geant4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
